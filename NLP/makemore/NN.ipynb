{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da0ab30-101a-486f-908c-e9819d41b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df594b1-67ed-4ee0-9fd9-4b888b6735bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = open('./data/names.txt', 'r').read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86f4a75-e49e-4f8c-ac0d-e186ff2d5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(names))))\n",
    "chars =  chars + [\".\"]\n",
    "\n",
    "c_to_ind = {c: i for i, c in enumerate(chars)}\n",
    "ind_to_c = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a81d51-866e-4d2b-9474-8a598f8c1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in names:\n",
    "    fnames = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(fnames, fnames[1:]):\n",
    "        ind1 = c_to_ind[ch1]\n",
    "        ind2 = c_to_ind[ch2]\n",
    "\n",
    "        xs.append(ind1)\n",
    "        ys.append(ind2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69df232e-46a8-406a-8c0c-1de0e723e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss: 3.9101641178131104\n",
      "Epoch 1: loss: 3.4949116706848145\n",
      "Epoch 2: loss: 3.2308170795440674\n",
      "Epoch 3: loss: 3.0640244483947754\n",
      "Epoch 4: loss: 2.956132650375366\n",
      "Epoch 5: loss: 2.8777856826782227\n",
      "Epoch 6: loss: 2.818321466445923\n",
      "Epoch 7: loss: 2.7715532779693604\n",
      "Epoch 8: loss: 2.733788251876831\n",
      "Epoch 9: loss: 2.7028534412384033\n",
      "Epoch 10: loss: 2.677318811416626\n",
      "Epoch 11: loss: 2.6560897827148438\n",
      "Epoch 12: loss: 2.6382734775543213\n",
      "Epoch 13: loss: 2.6231541633605957\n",
      "Epoch 14: loss: 2.6101722717285156\n",
      "Epoch 15: loss: 2.598902940750122\n",
      "Epoch 16: loss: 2.5890238285064697\n",
      "Epoch 17: loss: 2.580291271209717\n",
      "Epoch 18: loss: 2.5725209712982178\n",
      "Epoch 19: loss: 2.5655694007873535\n",
      "Epoch 20: loss: 2.5593245029449463\n",
      "Epoch 21: loss: 2.553694486618042\n",
      "Epoch 22: loss: 2.5486040115356445\n",
      "Epoch 23: loss: 2.543989419937134\n",
      "Epoch 24: loss: 2.5397942066192627\n",
      "Epoch 25: loss: 2.5359697341918945\n",
      "Epoch 26: loss: 2.5324742794036865\n",
      "Epoch 27: loss: 2.529268980026245\n",
      "Epoch 28: loss: 2.526320695877075\n",
      "Epoch 29: loss: 2.52359938621521\n",
      "Epoch 30: loss: 2.521080493927002\n",
      "Epoch 31: loss: 2.518740177154541\n",
      "Epoch 32: loss: 2.5165603160858154\n",
      "Epoch 33: loss: 2.5145230293273926\n",
      "Epoch 34: loss: 2.5126142501831055\n",
      "Epoch 35: loss: 2.5108208656311035\n",
      "Epoch 36: loss: 2.5091326236724854\n",
      "Epoch 37: loss: 2.5075385570526123\n",
      "Epoch 38: loss: 2.5060317516326904\n",
      "Epoch 39: loss: 2.5046045780181885\n",
      "Epoch 40: loss: 2.5032498836517334\n",
      "Epoch 41: loss: 2.501962900161743\n",
      "Epoch 42: loss: 2.5007383823394775\n",
      "Epoch 43: loss: 2.4995710849761963\n",
      "Epoch 44: loss: 2.498457670211792\n",
      "Epoch 45: loss: 2.497394561767578\n",
      "Epoch 46: loss: 2.496377944946289\n",
      "Epoch 47: loss: 2.495405435562134\n",
      "Epoch 48: loss: 2.494473457336426\n",
      "Epoch 49: loss: 2.4935803413391113\n",
      "Epoch 50: loss: 2.492723226547241\n",
      "Epoch 51: loss: 2.4919002056121826\n",
      "Epoch 52: loss: 2.4911093711853027\n",
      "Epoch 53: loss: 2.4903488159179688\n",
      "Epoch 54: loss: 2.489616632461548\n",
      "Epoch 55: loss: 2.4889118671417236\n",
      "Epoch 56: loss: 2.4882328510284424\n",
      "Epoch 57: loss: 2.4875779151916504\n",
      "Epoch 58: loss: 2.4869461059570312\n",
      "Epoch 59: loss: 2.4863359928131104\n",
      "Epoch 60: loss: 2.4857466220855713\n",
      "Epoch 61: loss: 2.4851770401000977\n",
      "Epoch 62: loss: 2.484626293182373\n",
      "Epoch 63: loss: 2.484093427658081\n",
      "Epoch 64: loss: 2.4835774898529053\n",
      "Epoch 65: loss: 2.4830780029296875\n",
      "Epoch 66: loss: 2.4825937747955322\n",
      "Epoch 67: loss: 2.4821243286132812\n",
      "Epoch 68: loss: 2.4816691875457764\n",
      "Epoch 69: loss: 2.481227397918701\n",
      "Epoch 70: loss: 2.4807987213134766\n",
      "Epoch 71: loss: 2.4803824424743652\n",
      "Epoch 72: loss: 2.47997784614563\n",
      "Epoch 73: loss: 2.4795844554901123\n",
      "Epoch 74: loss: 2.4792022705078125\n",
      "Epoch 75: loss: 2.478830337524414\n",
      "Epoch 76: loss: 2.478468656539917\n",
      "Epoch 77: loss: 2.478116273880005\n",
      "Epoch 78: loss: 2.477773666381836\n",
      "Epoch 79: loss: 2.4774398803710938\n",
      "Epoch 80: loss: 2.47711443901062\n",
      "Epoch 81: loss: 2.476797580718994\n",
      "Epoch 82: loss: 2.4764883518218994\n",
      "Epoch 83: loss: 2.476187229156494\n",
      "Epoch 84: loss: 2.475893259048462\n",
      "Epoch 85: loss: 2.475606679916382\n",
      "Epoch 86: loss: 2.4753265380859375\n",
      "Epoch 87: loss: 2.475053548812866\n",
      "Epoch 88: loss: 2.4747867584228516\n",
      "Epoch 89: loss: 2.4745264053344727\n",
      "Epoch 90: loss: 2.4742720127105713\n",
      "Epoch 91: loss: 2.4740231037139893\n",
      "Epoch 92: loss: 2.473780393600464\n",
      "Epoch 93: loss: 2.4735429286956787\n",
      "Epoch 94: loss: 2.473310708999634\n",
      "Epoch 95: loss: 2.47308349609375\n",
      "Epoch 96: loss: 2.4728612899780273\n",
      "Epoch 97: loss: 2.472644090652466\n",
      "Epoch 98: loss: 2.4724314212799072\n",
      "Epoch 99: loss: 2.4722230434417725\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "W = torch.randn((27, 27), requires_grad=True, generator=g)\n",
    "\n",
    "for epoch in range(100):\n",
    "    x_enc = F.one_hot(xs, num_classes=27)\n",
    "    x_enc = x_enc.to(torch.float32)\n",
    "    out = torch.mm(x_enc, W)\n",
    "    count = out.exp() \n",
    "    P = count / count.sum(dim=1, keepdims=True)\n",
    "    logP = P.log()\n",
    "    nll = -logP\n",
    "    ynll = nll[torch.arange(xs.size(-1)), ys]\n",
    "    loss = ynll.mean()\n",
    "\n",
    "    print(f\"Epoch {epoch}: loss: {loss.item()}\")\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data = W.data - 50*W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d30111-2a90-47e8-bb5b-92bb3cbe3ee1",
   "metadata": {},
   "source": [
    "## Sample from MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc5965f0-14fb-414e-9506-8fa2fa0d8671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: .aanaditanevayahyia, NLL: 2.9958\n",
      "Word: .dry, NLL: 3.3555\n",
      "Word: .zbannbronyanerayricarderiouwfdenilyxf, NLL: 3.4469\n",
      "Word: .se, NLL: 1.7117\n",
      "Word: .an, NLL: 1.7512\n",
      "Word: .massti, NLL: 2.5214\n",
      "Word: .meennnalllel, NLL: 2.7577\n",
      "Word: .et, NLL: 2.0445\n",
      "Word: .kaynyare, NLL: 2.7607\n",
      "Word: .d, NLL: 2.8152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.aanaditanevayahyia',\n",
       " '.dry',\n",
       " '.zbannbronyanerayricarderiouwfdenilyxf',\n",
       " '.se',\n",
       " '.an',\n",
       " '.massti',\n",
       " '.meennnalllel',\n",
       " '.et',\n",
       " '.kaynyare',\n",
       " '.d']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(1)\n",
    "\n",
    "new_names = []\n",
    "for name_ind in range(10):\n",
    "    log_likelihood = 0.0\n",
    "    p = torch.rand((1, 26))\n",
    "    start_ix = c_to_ind['.']\n",
    "    start_cix = ind_to_c[start_ix]\n",
    "    curr_word = [start_cix]\n",
    "    while True:\n",
    "        x_enc = F.one_hot(torch.tensor([c_to_ind[curr_word[-1]]]), num_classes=27).float()\n",
    "        # print(x_enc.shape)\n",
    "        logits = torch.mm(x_enc, W)\n",
    "        count = logits.exp()\n",
    "        p = count / count.sum(dim=1, keepdims=True)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        cix = ind_to_c[ix]\n",
    "        if cix == '.':\n",
    "            break\n",
    "        logprob = torch.log(P[c_to_ind[curr_word[-1]], ix])\n",
    "        log_likelihood += logprob\n",
    "        curr_word.append(cix)\n",
    "    new_names.append(\"\".join(curr_word))\n",
    "    nll = -log_likelihood\n",
    "    print(f\"Word: {new_names[-1]}, NLL: {nll/len(new_names[-1]):.4f}\")\n",
    "    \n",
    "\n",
    "new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce22b5-d5e6-4648-8585-0cefc50bd48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
